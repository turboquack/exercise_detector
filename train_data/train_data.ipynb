{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896243b5-36d0-4072-91fd-25d3f5ac1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Set a fixed random seed value, for reproducibility\n",
    "SEED = 2137\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# list of exercises files\n",
    "EXERCISES = [\n",
    "    \"biceps_curl_1\",\n",
    "    \"triceps_ext\",\n",
    "    \"noise2\",\n",
    "    \"shoulder_side\",\n",
    "    \"shoulder_front\"\n",
    "]\n",
    "#SPECIFY DATA LOCATION\n",
    "dataset_path = \"/home/dev/data\"\n",
    "\n",
    "SAMPLES_PER_EXERCISES = 297\n",
    "\n",
    "NUM_OF_EXERCISES = len(EXERCISES)\n",
    "\n",
    "# output matrix\n",
    "ONE_HOT_ENCODED_EXERCISES = np.eye(NUM_OF_EXERCISES)\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# reading every csv file and putting it into input and output\n",
    "for exercise_index in range(NUM_OF_EXERCISES):\n",
    "  gesture = EXERCISES[exercise_index]\n",
    "  print(f\"Processing index {exercise_index} for gesture '{gesture}'.\")\n",
    "  \n",
    "  output = ONE_HOT_ENCODED_EXERCISES[exercise_index]\n",
    "  \n",
    "  df = pd.read_csv(dataset_path + gesture + \".csv\")\n",
    "  \n",
    "  # calculate the number of gesture recordings in the file\n",
    "  num_recordings = int(df.shape[0] / SAMPLES_PER_EXERCISES)\n",
    "  \n",
    "  print(f\"\\tThere are {num_recordings} recordings of the {gesture} exercise.\")\n",
    "  \n",
    "  for i in range(num_recordings):\n",
    "    tensor = []\n",
    "    for j in range(SAMPLES_PER_EXERCISES):\n",
    "      index = i * SAMPLES_PER_EXERCISES + j\n",
    "      # normalize the input data, between 0 to 1:\n",
    "      # - acceleration is between: -4 to +4\n",
    "      # - gyroscope is between: -2000 to +2000\n",
    "      tensor += [\n",
    "          (df['aX'][index] + 4) / 8,\n",
    "          (df['aY'][index] + 4) / 8,\n",
    "          (df['aZ'][index] + 4) / 8,\n",
    "          (df['gX'][index] + 2000) / 4000,\n",
    "          (df['gY'][index] + 2000) / 4000,\n",
    "          (df['gZ'][index] + 2000) / 4000\n",
    "      ]\n",
    "\n",
    "    inputs.append(tensor)\n",
    "    outputs.append(output)\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "outputs = np.array(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee41c9c-9437-47f2-a52f-4df4e8545586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
    "num_inputs = len(inputs)\n",
    "randomize = np.arange(num_inputs)\n",
    "np.random.shuffle(randomize)\n",
    "# Swap the consecutive indexes with the randomized indexes\n",
    "inputs = inputs[randomize]\n",
    "outputs = outputs[randomize]\n",
    "# Split into three sets: training, testing and validation\n",
    "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
    "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
    "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876d54e-214f-4945-85fe-0876c40dc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model and train it\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu')) \n",
    "model.add(tf.keras.layers.Dense(NUM_OF_EXERCISES, activation='softmax')) \n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "history = model.fit(inputs_train, outputs_train, epochs=700, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
    "model.save('/home/trep/data/keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237000f-782d-4680-9170-6d2860590a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "#optimizing\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"exercise_model.tflite\", \"wb\").write(tflite_model)\n",
    "  \n",
    "import os\n",
    "basic_model_size = os.path.getsize(\"exercise_model.tflite\")\n",
    "print(\"Model is %d bytes\" % basic_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc0274-1788-4d06-98f2-edf47f4854fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > /home/dev/data/model.h\n",
    "!cat exercise_model.tflite | xxd -i      >> /home/dev/data/model.h\n",
    "!echo \"};\"                              >> /home/dev/data/model.h\n",
    "\n",
    "import os\n",
    "model_h_size = os.path.getsize(\"model.h\")\n",
    "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
